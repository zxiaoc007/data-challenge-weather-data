{"cells":[{"cell_type":"code","source":["# Import libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# Create a Spark Session\nspark = SparkSession \\\n        .builder \\\n        .appName('whether data exploration') \\\n        .getOrCreate()\nprint('Session created')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Session created\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Display all the files in the folder\nfiles = dbutils.fs.ls(\"/FileStore/tables/new/\")\ndisplay(files)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/new/countrylist.csv</td><td>countrylist.csv</td><td>4373</td></tr><tr><td>dbfs:/FileStore/tables/new/part_00000_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>part_00000_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>19893364</td></tr><tr><td>dbfs:/FileStore/tables/new/part_00001_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>part_00001_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>18748869</td></tr><tr><td>dbfs:/FileStore/tables/new/part_00002_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>part_00002_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>17572400</td></tr><tr><td>dbfs:/FileStore/tables/new/part_00003_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>part_00003_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>15481340</td></tr><tr><td>dbfs:/FileStore/tables/new/part_00004_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>part_00004_890686c0_c142_4c69_a744_dfdc9eca7df4_c000_csv.gz</td><td>9625851</td></tr><tr><td>dbfs:/FileStore/tables/new/stationlist.csv</td><td>stationlist.csv</td><td>253080</td></tr></tbody></table></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# File location\nfile_location = \"/FileStore/tables/new/*.gz\"\n\n# Define column type\nSchema = StructType([\n  StructField(\"STN---\", IntegerType(), True),\n  StructField(\"WBAN\", IntegerType(), True),\n  StructField(\"YEARMODA\", IntegerType(), True),\n  StructField(\"TEMP\", DoubleType(), True),\n  StructField(\"DEWP\", DoubleType(), True),\n  StructField(\"SLP\", DoubleType(), True),\n  StructField(\"STP\", DoubleType(), True),\n  StructField(\"VISIB\", DoubleType(), True),\n  StructField(\"WDSP\", DoubleType(), True),\n  StructField(\"MXSPD\", DoubleType(), True),\n  StructField(\"GUST\", DoubleType(), True),\n  StructField(\"MAX\", DoubleType(), True),\n  StructField(\"MIN\", DoubleType(), True),\n  StructField(\"PRCP\", DoubleType(), True),\n  StructField(\"SNDP\", DoubleType(), True),\n  StructField(\"FRSHTT\", StringType(), True)\n])\n\n# Load data\ndf = (\n  spark.read\n  .option(\"header\", \"true\")\n  .option(\"delimiter\", \",\")\n  .schema(Schema) # Use the specified schema\n  .csv(file_location)\n)\n\n# Display data\ndf.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-----+--------+----+----+------+------+-----+----+-----+----+----+----+----+-----+------+\nSTN---| WBAN|YEARMODA|TEMP|DEWP|   SLP|   STP|VISIB|WDSP|MXSPD|GUST| MAX| MIN|PRCP| SNDP|FRSHTT|\n+------+-----+--------+----+----+------+------+-----+----+-----+----+----+----+----+-----+------+\n 10260|99999|20190101|26.1|21.2|1001.9| 987.5| 20.6| 9.0| 15.9|29.7|29.8|null|null| 18.5|001000|\n 10260|99999|20190102|24.9|22.1|1020.1|1005.5|  5.4| 5.6| 13.6|22.1|null|20.7|null| 22.8|001000|\n 10260|99999|20190103|31.7|29.1|1008.9| 994.7| 13.6|11.6| 21.4|49.5|null|null|null|999.9|011000|\n 10260|99999|20190104|32.9|30.3|1011.4| 997.1| 15.8| 4.9|  7.8|10.9|36.1|31.8|null|999.9|001000|\n 10260|99999|20190105|35.5|33.0|1015.7|1001.4| 12.0|10.4| 13.6|21.0|null|32.7|null| 23.6|010000|\n+------+-----+--------+----+----+------+------+-----+----+-----+----+----+----+----+-----+------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Impute null with exact missing values\ndf = df.fillna({'TEMP':'9999.9'})\ndf = df.fillna({'DEWP':'9999.9'})\ndf = df.fillna({'SLP':'9999.9'})\ndf = df.fillna({'STP':'9999.9'})\ndf = df.fillna({'VISIB':'999.9'})\ndf = df.fillna({'WDSP':'999.9'})\ndf = df.fillna({'MXSPD':'999.9'})\ndf = df.fillna({'GUST':'999.9'})\ndf = df.fillna({'MAX':'9999.9'})\ndf = df.fillna({'MIN':'9999.9'})\ndf = df.fillna({'PRCP':'99.99'})\ndf = df.fillna({'SNDP':'999.9'})\n# Display data\ndf.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-----+--------+----+----+------+------+-----+----+-----+----+------+------+-----+-----+------+\nSTN---| WBAN|YEARMODA|TEMP|DEWP|   SLP|   STP|VISIB|WDSP|MXSPD|GUST|   MAX|   MIN| PRCP| SNDP|FRSHTT|\n+------+-----+--------+----+----+------+------+-----+----+-----+----+------+------+-----+-----+------+\n 10260|99999|20190101|26.1|21.2|1001.9| 987.5| 20.6| 9.0| 15.9|29.7|  29.8|9999.9|99.99| 18.5|001000|\n 10260|99999|20190102|24.9|22.1|1020.1|1005.5|  5.4| 5.6| 13.6|22.1|9999.9|  20.7|99.99| 22.8|001000|\n 10260|99999|20190103|31.7|29.1|1008.9| 994.7| 13.6|11.6| 21.4|49.5|9999.9|9999.9|99.99|999.9|011000|\n 10260|99999|20190104|32.9|30.3|1011.4| 997.1| 15.8| 4.9|  7.8|10.9|  36.1|  31.8|99.99|999.9|001000|\n 10260|99999|20190105|35.5|33.0|1015.7|1001.4| 12.0|10.4| 13.6|21.0|9999.9|  32.7|99.99| 23.6|010000|\n+------+-----+--------+----+----+------+------+-----+----+-----+----+------+------+-----+-----+------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Load country list data\n\n# File location\nfile_location = \"/FileStore/tables/new/countrylist.csv\"\n\n# Load data\ndf_country = (\n  spark.read\n  .option(\"header\", \"true\")\n  .option(\"delimiter\", \",\")\n  .option(\"inferSchema\", \"true\")  # Automatically infer data types\n  .csv(file_location)\n)\n\n# Display data\ndf_country.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+-------------------+\nCOUNTRY_ABBR|       COUNTRY_FULL|\n+------------+-------------------+\n          AA|              ARUBA|\n          AC|ANTIGUA AND BARBUDA|\n          AF|        AFGHANISTAN|\n          AG|            ALGERIA|\n          AI|   ASCENSION ISLAND|\n+------------+-------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Load station list data\n# File location\nfile_location = \"/FileStore/tables/new/stationlist.csv\"\n\n# Load data\ndf_station = (\n  spark.read\n  .option(\"header\", \"true\")\n  .option(\"delimiter\", \",\")\n  .option(\"inferSchema\", \"true\")  # Automatically infer data types\n  .csv(file_location)\n)\n\n# Display data\ndf_station.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+-------------------+\nCOUNTRY_ABBR|       COUNTRY_FULL|\n+------------+-------------------+\n          AA|              ARUBA|\n          AC|ANTIGUA AND BARBUDA|\n          AF|        AFGHANISTAN|\n          AG|            ALGERIA|\n          AI|   ASCENSION ISLAND|\n+------------+-------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Join station data with full country name\nstation_country = df_station.join(df_country, on=['COUNTRY_ABBR'], how='left')\nstation_country = station_country.withColumn(\"STN_NO\", station_country[\"STN_NO\"].cast(IntegerType()))\nstation_country.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+------+--------------+\nCOUNTRY_ABBR|STN_NO|  COUNTRY_FULL|\n+------------+------+--------------+\n          NO| 12240|        NORWAY|\n          SW| 20690|        SWEDEN|\n          SW| 20870|        SWEDEN|\n          SW| 21190|        SWEDEN|\n          UK| 32690|UNITED KINGDOM|\n+------------+------+--------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Join weather data with full country names by station number \ndf_joined = df.join(station_country, df['STN---'] == station_country['STN_NO'], how='left')\ndf_joined.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Get answer to the questions\n\navg_temp = (\n  df_joined\n  .filter('TEMP != 9999.9')\n  .groupBy(col('COUNTRY_FULL'))\n  .agg(avg('TEMP').alias('AVG_TEMP'))\n  .sort(col('AVG_TEMP').desc())\n)\n\n# Question 1\nprint('Country had the hottest average mean temperature over the year:')\nprint(avg_temp.head(1))\n\n# Question 2\nprint('Country had the coldest average mean temperature over the year:')\nprint(avg_temp.tail(1))\n\n# Question 3\nprint('Country had the second highest average mean wind speed over the year:')\nprint(\n  df_joined\n  .filter('WDSP != 999.9')\n  .groupBy(col('COUNTRY_FULL'))\n  .agg(avg('WDSP').alias('AVG_WDSP'))\n  .sort(col('AVG_WDSP').desc())\n  .collect()[1]\n)\n\n# Question 4\nprint('Country had the most consecutive days of tornadoes/funnel cloud formations:')\ndf_joined = df_joined.withColumn(\"lastchar\", df_joined.FRSHTT.substr(-1,1))\nprint(\n  df_joined\n  .filter(\"lastchar = '1'\")\n  .groupBy(col('COUNTRY_FULL'))\n  .agg(sum('lastchar').alias('SUM_TOR'))\n  .head(1)\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Country had the hottest average mean temperature over the year:\n[Row(COUNTRY_FULL=&#39;DJIBOUTI&#39;, AVG_TEMP=90.06114457831325)]\nCountry had the coldest average mean temperature over the year:\n[Row(COUNTRY_FULL=&#39;ANTARCTICA&#39;, AVG_TEMP=-2.8328838863485393)]\nCountry had the second highest average mean wind speed over the year:\nRow(COUNTRY_FULL=&#39;ARUBA&#39;, AVG_WDSP=15.975683060109283)\nCountry had the most consecutive days of tornadoes/funnel cloud formations:\n[Row(COUNTRY_FULL=&#39;JAPAN&#39;, SUM_TOR=11.0)]\n</div>"]}}],"execution_count":10}],"metadata":{"name":"whether_data","notebookId":545945657956974},"nbformat":4,"nbformat_minor":0}
